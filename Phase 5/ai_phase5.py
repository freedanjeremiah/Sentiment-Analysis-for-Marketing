# -*- coding: utf-8 -*-
"""AI_Phase5

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/17zpC8EUol0hVPa89TPgUe4tb-opUkp6A
"""

import numpy as np
import pandas as pd
!pip install transformers
import transformers
import torch

data = pd.read_csv("Tweets.csv")

data.sample(9)

data.tail(9)

data.isnull()

data.isnull().sum()

data.info()

data.dtypes

data.columns

import re
import nltk
from nltk.corpus import stopwords
from nltk.tokenize import word_tokenize
from nltk.stem import PorterStemmer
nltk.download('stopwords')
# Download the 'punkt' resource
nltk.download('punkt')

# Function for text preprocessing
def preprocess_text(text):
    # Remove special characters, numbers, and convert to lowercase
    text = re.sub(r'[^a-zA-Z]', ' ', text)
    text = text.lower()

    # Tokenize the text
    words = word_tokenize(text)

    # Remove stop words and apply stemming
    stop_words = set(stopwords.words('english'))
    ps = PorterStemmer()
    words = [ps.stem(word) for word in words if word not in stop_words]

    return ' '.join(words)

# Apply preprocessing to your text data
data['cleaned_text'] = data['text'].apply(preprocess_text)

data

from sklearn.feature_extraction.text import TfidfVectorizer

# Create TF-IDF vectorizer
tfidf_vectorizer = TfidfVectorizer(max_features=5000)

# Fit and transform your cleaned text data into numerical features
X = tfidf_vectorizer.fit_transform(data['cleaned_text'])
print(X)

from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, data['airline_sentiment'], test_size=0.2, random_state=42)

# Create and train a Logistic Regression model
model = LogisticRegression()
model.fit(X_train, y_train)

# Make predictions
y_pred = model.predict(X_test)

# Evaluate the model
accuracy = accuracy_score(y_test, y_pred)
print(f"Accuracy: {accuracy}")

# Calculate the distribution of sentiment
sentiment_distribution = data['airline_sentiment'].value_counts()

# Most common reasons for negative sentiments
common_negative_reasons = data[data['airline_sentiment'] == 'negative']['negativereason'].value_counts()

# Analyze the impact of airline sentiment confidence
data['airline_sentiment_confidence'].groupby(data['airline_sentiment']).mean()

# Explore the relationship between sentiment and airline
sentiment_by_airline = data.groupby(['airline', 'airline_sentiment']).size().unstack()

sentiment_by_airline

from gensim.models import Word2Vec

# Tokenize the cleaned text data
tokenized_data = data['cleaned_text'].apply(lambda x: x.split())

# Train a Word2Vec model
w2v_model = Word2Vec(sentences=tokenized_data, vector_size=100, window=5, min_count=1, sg=0)

# Find similar words
similar_words = w2v_model.wv.most_similar('flight', topn=5)
print("Words similar to 'flight':", similar_words)

import seaborn as sns
import matplotlib.pyplot as plt

sns.countplot(data=data, x='airline_sentiment', hue='airline')
plt.title("Sentiment Distribution by Airline")
plt.show()

import plotly.express as px

fig = px.scatter(data, x='retweet_count', y='airline_sentiment', color='airline_sentiment')
fig.update_layout(title="Interactive Scatter Plot")
fig.show()

import plotly.express as px

fig = px.box(data, x='airline', y='airline_sentiment_confidence', color='airline_sentiment')
fig.update_layout(title="Interactive Box Plot by Airline and Sentiment")
fig.show()

import plotly.express as px

fig = px.bar(data, x='airline', y='tweet_location', color='airline_sentiment',
             labels={'count': 'Sentiment Count'},
             title="Sentiment Distribution by Airline")
fig.show()

import plotly.express as px

fig = px.sunburst(data, path=['airline', 'airline_sentiment'], values='airline_sentiment_confidence',
                 title="Sentiment Breakdown by Airline")
fig.show()

import pandas as pd
import plotly.express as px

# Select numeric columns from your dataset
numeric_data = data.select_dtypes(include='number')

# Calculate the correlation matrix for numeric columns
correlation = numeric_data.corr()

# Create an interactive heatmap to visualize correlations
fig = px.imshow(correlation, x=correlation.columns, y=correlation.columns, color_continuous_scale='Viridis',
                labels=dict(color="Correlation"))
fig.update_layout(title="Correlation Heatmap for Numeric Columns")
fig.show()

import matplotlib.pyplot as plt
plt.scatter(data.tweet_id, data.airline_sentiment_confidence)

import matplotlib.pyplot as plt
import pandas as pd
plt.figure(figsize=(8, 6))
plt.boxplot(data['airline_sentiment_confidence'], vert=False)
plt.title('Box Plot of Airline Sentiment Confidence')
plt.xlabel('Confidence')
plt.yticks([])
plt.show()

import matplotlib.pyplot as plt
import pandas as pd
sentiment_counts = data['airline_sentiment'].value_counts()
plt.figure(figsize=(8, 6))
plt.pie(sentiment_counts, labels=sentiment_counts.index, autopct='%1.1f%%', startangle=140)
plt.title('Distribution of Airline Sentiments')
plt.axis('equal')
plt.show()

plt.figure(figsize=(8, 6))
plt.hist(data['airline_sentiment_confidence'], bins=20, edgecolor='k')
plt.title('Distribution of Airline Sentiment Confidence')
plt.xlabel('Confidence')
plt.ylabel('Frequency')
plt.show()
plt.figure(figsize=(8, 6))
plt.hist(data['retweet_count'], bins=20, edgecolor='k')
plt.title('Distribution of Retweet Count')
plt.xlabel('Retweet Count')
plt.ylabel('Frequency')
plt.show()

airline_counts = data['airline'].value_counts()
plt.figure(figsize=(10, 6))
plt.bar(airline_counts.index, airline_counts.values)
plt.title('Distribution of Airlines')
plt.xlabel('Airline')
plt.ylabel('Count')
plt.xticks(rotation=45)
plt.show()

negativereason_counts = data['negativereason'].value_counts()
plt.figure(figsize=(12, 6))
plt.bar(negativereason_counts.index, negativereason_counts.values)
plt.title('Distribution of Negative Reasons')
plt.xlabel('Negative Reason')
plt.ylabel('Count')
plt.xticks(rotation=90)
plt.show()

import matplotlib.pyplot as plt
import seaborn as sns

sns.countplot(data=data, x='airline_sentiment')
plt.title("Distribution of Sentiment Classes")
plt.show()

from wordcloud import WordCloud

text = " ".join(tweet for tweet in data['text'])
wordcloud = WordCloud(width=800, height=400, background_color='white').generate(text)

plt.figure(figsize=(10, 5))
plt.imshow(wordcloud, interpolation='bilinear')
plt.axis("off")
plt.title("Word Cloud for Tweets")
plt.show()

data['tweet_length'] = data['text'].apply(len)
plt.hist(data['tweet_length'], bins=20)
plt.title("Distribution of Tweet Lengths")
plt.xlabel("Tweet Length")
plt.ylabel("Frequency")
plt.show()

import re

hashtags = [tag for tweet in data['text'] for tag in re.findall(r'#\w+', tweet)]
mentions = [mention for tweet in data['text'] for mention in re.findall(r'@\w+', tweet)]

# Top hashtags
top_hashtags = pd.Series(hashtags).value_counts()[:10]
top_hashtags.plot(kind='bar', title="Top Hashtags")
plt.show()

# Top mentions
top_mentions = pd.Series(mentions).value_counts()[:10]
top_mentions.plot(kind='bar', title="Top Mentions")
plt.show()

import re
import nltk
from nltk.corpus import stopwords
from nltk.tokenize import word_tokenize
from nltk.stem import PorterStemmer
nltk.download('stopwords')
# Download the 'punkt' resource
nltk.download('punkt')

# Function for text preprocessing
def preprocess_text(text):
    # Remove special characters, numbers, and convert to lowercase
    text = re.sub(r'[^a-zA-Z]', ' ', text)
    text = text.lower()

    # Tokenize the text
    words = word_tokenize(text)

    # Remove stop words and apply stemming
    stop_words = set(stopwords.words('english'))
    ps = PorterStemmer()
    words = [ps.stem(word) for word in words if word not in stop_words]

    return ' '.join(words)

# Apply preprocessing to your text data
data['cleaned_text'] = data['text'].apply(preprocess_text)

from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, data['airline_sentiment'], test_size=0.2, random_state=42)

# Create and train a Logistic Regression model
model = LogisticRegression()
model.fit(X_train, y_train)

# Make predictions
y_pred = model.predict(X_test)

# Evaluate the model
accuracy = accuracy_score(y_test, y_pred)
print(f"Accuracy: {accuracy}")

# Calculate the distribution of sentiment
sentiment_distribution = data['airline_sentiment'].value_counts()

# Most common reasons for negative sentiments
common_negative_reasons = data[data['airline_sentiment'] == 'negative']['negativereason'].value_counts()

# Analyze the impact of airline sentiment confidence
data['airline_sentiment_confidence'].groupby(data['airline_sentiment']).mean()

# Explore the relationship between sentiment and airline
sentiment_by_airline = data.groupby(['airline', 'airline_sentiment']).size().unstack()

sentiment_by_airline

!pip install pandas textblob

import pandas as pd
from textblob import TextBlob


# Define a function to get sentiment polarity and subjectivity
def get_sentiment(text):
    analysis = TextBlob(text)
    if analysis.sentiment.polarity > 0:
        return 'positive'
    elif analysis.sentiment.polarity < 0:
        return 'negative'
    else:
        return 'neutral'

# Apply sentiment analysis to the 'text' column and create a new 'sentiment' column
data['sentiment'] = data['text'].apply(get_sentiment)

# Display the resulting DataFrame with sentiment labels
print(data[['tweet_id', 'text', 'sentiment']])

# Create a summary table
sentiment_summary = data['sentiment'].value_counts().reset_index()
sentiment_summary.columns = ['Sentiment', 'Count']

# Display the table
print(sentiment_summary)

# Show the chart
plt.show()

# Create a bar chart to visualize sentiment distribution
sentiment_counts = data['sentiment'].value_counts()
plt.figure(figsize=(8, 6))
plt.bar(sentiment_counts.index, sentiment_counts.values, color=['green', 'red', 'blue'])
plt.title('Sentiment Distribution')
plt.xlabel('Sentiment')
plt.ylabel('Count')

